{
    "hidden_layers": 2,
    "neurons_per_layer": 64,
    "activation_hidden": "relu",
    "activation_output": "linear",
    "batch_size": 32,
    "epochs": 20,
    "learning_rate": 0.001
  }
  
